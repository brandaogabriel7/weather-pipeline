x-airflow-common: &airflow-common
  image: apache/airflow:2.10.4
  environment: &airflow-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:postgres@db:5432/airflow_db
    DB_HOST: db
    DB_PORT: "5432"
    DB_NAME: weather_db
    DB_USER: postgres
    DB_PASSWORD: postgres
  volumes:
    - ./dags:/opt/airflow/dags
    - ./src:/opt/airflow/dags/src
    - ./config:/opt/airflow/dags/config
    - ./logs:/opt/airflow/logs
  depends_on:
    db:
      condition: service_healthy

services:
  db:
    image: postgres:latest
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: weather_db
    ports:
      - "5432:5432"
    volumes:
      - ./db-init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command:
      - -c
      - |
        pip install pandas psycopg2-binary requests --quiet &&
        airflow db migrate &&
        airflow users create \
          --username admin \
          --password admin \
          --firstname Admin \
          --lastname User \
          --role Admin \
          --email admin@example.com || true
    restart: "no"

  airflow-webserver:
    <<: *airflow-common
    command: >
      bash -c "pip install pandas psycopg2-binary requests --quiet && airflow webserver"
    ports:
      - "8080:8080"
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    restart: unless-stopped

  airflow-scheduler:
    <<: *airflow-common
    command: >
      bash -c "pip install pandas psycopg2-binary requests --quiet && airflow scheduler"
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    restart: unless-stopped
